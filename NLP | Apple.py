# -*- coding: utf-8 -*-
"""Apple | NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17cdYKpu6OhFaHFjYyo97GCmOamM9jwIf
"""

# Commented out IPython magic to ensure Python compatibility.
#Load libraries essential for NLP 
import pandas as pd
import datetime
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns


from sklearn.feature_extraction.text import CountVectorizer 
from sklearn.decomposition import TruncatedSVD
from sklearn.decomposition import NMF

from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"

#The objective of this project is to analyze Twitter Customer Support dataset leveraging NLP techniques .
#It will primarily focus on @AppleSupport
CST = pd.read_csv('/content/sample_data/twcs.csv', nrows = 200000,)
CST.head(2)

#Apple subset
AppleSupport = ['AppleSupport']

#Create dataframe with Apple related data point
Apple = CST[CST['author_id'].isin(AppleSupport) | CST['text'].str.contains('AppleSupport')] 
Apple.reset_index(drop = True, inplace= True)

#Check changes
Apple.head(2)

#Convert 'created_at' to date timestamp and create Year, Month, Day columns
Apple['created_at'] = Apple['created_at'].astype('datetime64[ns]')
Apple['Year'] = pd.DatetimeIndex(Apple['created_at']).year
Apple['Month'] = pd.DatetimeIndex(Apple['created_at']).month
Apple['Day'] =  pd.DatetimeIndex(Apple['created_at']).day
Apple['Hour_Created'] = Apple.created_at.dt.hour

#Drop 'created_at column
Apple.drop(["created_at"], axis=1, inplace=True)

#Change 'text' to type string
Apple['text'] = Apple['text'].astype(str)

pip install emoji --upgrade

#Function to remove twitter @handles and url's
import re
import emoji

def preprocess(text):
  
  text = re.sub('(@\S*)','', text)
  text = re.sub('https\S*', '', text)
  
  return text

#Check changes
Apple.head(2)

#Apply preprocess function
#Create new column with clean text

Apple['Clean_text'] = Apple['text'].apply(preprocess)

#Convert emoji's into text
Apple["Clean_text"] = Apple['Clean_text'].apply(lambda x : emoji.demojize( x, delimiters=('', '')))

#Test if emoji transformations are successful
Apple.iloc[38 , 3]
print('\n')
Apple.iloc[38 , 10]

#Test if link transformations are successful
Apple.iloc[4 , 3]
print('\n')
Apple.iloc[4 , 10]

from nltk.corpus import stopwords 

#Count Vectorizer
vectorizer = CountVectorizer(stop_words = 'english', min_df = 6)
Apple_text_vectorized = vectorizer.fit_transform(Apple['Clean_text'])
Apple_text_vectorized.shape

Apple_words = pd.DataFrame(Apple_text_vectorized.toarray(),columns = vectorizer.get_feature_names())
Apple_words.head(2)

#Creating a randomized_svd
from sklearn.utils.extmath import randomized_svd

U, Sigma, VT = randomized_svd(Apple_text_vectorized, n_components=15,
                                      n_iter=5,
                                      random_state=None)

#Sigma array
Sigma

#Plot Sigma results
plt.plot(range(1,16),Sigma)
plt.show()

#NMF topic model
from sklearn.decomposition import NMF

#Creating model for 8 topics
nmf_model = NMF(8)
Apple_topics = nmf_model.fit_transform(Apple_text_vectorized)

#Arg sort on components
words = vectorizer.get_feature_names()

t = nmf_model.components_.argsort(axis=1)[:,-1:-8:-1]
topic_words = [[words[e] for e in l] for l in t]
topic_words

#Function to label topics
def display_topics(model, feature_names, no_top_words, topic_names= ['Apple Resolution Attempts','iOS Status','Functionality Inquiries','Communication Preference','Troubleshoot','iPhone Support','General Inquiries','Application Support']):
    for ix, topic in enumerate(model.components_):
        if not topic_names or not topic_names[ix]:
            print("\nTopic ", ix)
        else:
            print("\nTopic: '",topic_names[ix],"'")
        print(", ".join([feature_names[i]
                        for i in topic.argsort()[:-no_top_words - 1:-1]]))

#Display topics with respective words
display_topics(nmf_model, vectorizer.get_feature_names(), 30)

#Loop through list components for topics
Topic_list = ['Apple Resolution Attempts','iOS Status','Functionality Inquiries','Communication Preference','Troubleshoot','iPhone Support','General Inquiries','Application Support']
Apple['topics'] = [Topic_list[i] for i in Apple_topics.argmax(axis = 1)]
Apple.head(2)

pip install vaderSentiment

#Create sentiment analysis
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

analyzer = SentimentIntensityAnalyzer()

Apple['Sentiment'] = Apple['Clean_text'].apply(lambda Text: analyzer.polarity_scores(Text))

#Create respective sentiment columns
Apple['Sentiment_negative'] = Apple['Sentiment'].apply(lambda x: x['neg'])
Apple['Sentiment_neutral'] = Apple['Sentiment'].apply(lambda x: x['neu'])
Apple['Sentiment_positive'] = Apple['Sentiment'].apply(lambda x: x['pos'])
Apple['Sentiment_compound'] = Apple['Sentiment'].apply(lambda x: x['compound'])

#Drop null values
Apple.dropna(inplace=True)

#Check changes
Apple.head(4)

#Excel export to create Tableau dashboard
Apple.to_excel("Apple_tweets.xlsx",
              sheet_name='Apple_tweets')

pip install scattertext

#Building scattertext
import scattertext as st

corpus = st.CorpusFromPandas(Apple,
                             category_col='author_id',
                             text_col= 'Clean_text',
                             nlp=st.whitespace_nlp_with_sentences
                            ).build()

#Generate url for scattertext
html = st.produce_scattertext_explorer(
        corpus,
        category='AppleSupport',
        category_name='AppleSupport',
        not_category_name='Customer Inquires',
        minimum_term_frequency=10,
        pmi_threshold_coefficient=5,
        width_in_pixels=1000
        )

open('Apple.html', 'wb').write(html.encode('utf-8'));